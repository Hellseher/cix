# File           : cix-wget.org
# Created        : <2016-11-21 Mon 21:11:14 GMT>
# Modified  : <2017-9-03 Sun 22:41:38 BST> sharlatan
# Author         : sharlatan
# Maintainer(s)  :
# Sinopsis : A utility for retrieving files using the HTTP or FTP protocols.

#+OPTIONS: num:nil

[[file:../cix-main.org][|≣|]]
#+TITLE: wget
|-----------------+------------------------|
| *Author*        | Hrvoje Nikšić [[https://git.savannah.gnu.org/cgit/wget.git/tree/AUTHORS][(all...)]] |
| *Maintainer(s)* |                        |
| *Released*      | 1996                   |
| *Source*        | [[https://git.savannah.gnu.org/cgit/wget.git][wget.git]]               |
| *Man*           |                        |
| *Info*          |                        |
|-----------------+------------------------|

GNU  Wget is  a file  retrieval utility  which can  use either  the HTTP  or FTP
protocols. Wget features include the ability to work in the background while you
are logged out, recursive retrieval of directories, file name wildcard matching,
remote file timestamp  storage and comparison, use of Rest  with FTP servers and
Range with  HTTP servers to  retrieve files  over slow or  unstable connections,
support for Proxy servers, and configurability.
-----

* Receipts
** wget                                                                         :cmd:
*** wgre::options
| p |   |
| e |   |
*** wget::examples
**** wget-161127222725
download an entire website:
:    ~ $  wget --random-wait -r -p -e robots=off -U mozilla WEBSITE_URL

**** wget-161121211338
download a sertain file in a list of files from a server with known structure:

#+BEGIN_SRC sh
  #!/usr/bin/env bash

  URL="https://dumps.wikimedia.org/other/pageviews/2016/2016-01/"
  FILE_RE="(?<=\<a href\=\").+(?=\"\>)"

  declare -a FILE_NAMES
  FILE_NAMES=($(curl -s "$URL" | grep -oP "$FILE_RE"))

  wget "$URL${FILE_NAMES[2]}"
#+END_SRC
declare [[file::*curl][curl (1)]] [[file:./cix-gnu-grep.org::*grep][grep (1)]]

# End of cix-wget.org
